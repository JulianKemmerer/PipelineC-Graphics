\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage{flushend}
\usepackage{listings}
\lstset{frame=tb,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny,
  breaklines=true,
  breakatwhitespace=true,
  tabsize=2
}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Sphery vs. Shapes: A hardware-only raytraced game\\

\author{
\IEEEauthorblockN{1\textsuperscript{st} Victor Suarez Rovere}
Buenos Aires, Argentina \\
suarezvictor@gmail.com
\and
\IEEEauthorblockN{2\textsuperscript{nd} Julian Kemmerer}
Philadelphia, USA \\
julian.v.kemmerer@gmail.com
}}

\maketitle

\begin{abstract}
In this article we present a tool flow that takes C++ code describing a raytraced game, and produces digital logic that can be implemented in an off-the-shelf FPGA with no use of a hard or soft CPU. We aim for these tools to achieve a friendly C-to-FPGA flow, making the development and simulation process exceptionally fast and easy, while providing high performance and low power results in hardware.
\end{abstract}

\begin{IEEEkeywords}
FPGA, raytracing, DSP, simulation
\end{IEEEkeywords}

\section{Introduction}
In this work we propose a interactive ray tracing system implemented entirely in hardware using a FPGA (Field Programmable Gate Array). It  serves as a perfect example that such complex data processing circuits can be developed, tested, and implemented all from a C language based flow. This greatly eases the design process over traditional hardware description languages.

The ability to compile the sources directly as C++ code allows for ultra-fast prototype testing (up to realtime speeds). C++ based cycle accurate emulation tools like Verilator\cite{verilator} allow for fast simlations, but at a pace that is still much slower than directly compiled C code. A truely realtime simulation workflow is essential for developing an interactive game: to compile-as-C and see the results of code changes executed in realtime is not possible with standard FPGA simulators or synthesis tools.

The project generates each video pixel in hard-realtime “chasing the beam” fashion, without a frame buffer and with negligible jitter. Two medium size FPGA devices were selected for implementation: An  AMD\textsuperscript{TM}  Artix-7\textsuperscript{TM} (100T) and a Lattice\textsuperscript{TM}  ECP5\textsuperscript{TM} (85F). By using many pipeline stages automatically generated by a custom tool, clock rates high enough for playable speeds are possible.

This article is structured with the following sections: hardware platforms and software components are detailed, followed by methods used in the form of a workflow of tools. A final section describes the results obtained in regards to running times, graphics resolution, pipeline depth and power consumption.
\\

\section{Materials and methods}
This work integrates software and hardware components in a custom workflow that processes C sources through to generating the programmable logic device configuration.

\subsection{Hardware Architecture}
The project was tested on two off-the-shelf FPGA boards:

\begin{itemize}
\item A fully open source board based on a Lattice ECP5 FPGA with 85K LE. A Digilent\textsuperscript{TM} PMOD\textsuperscript{TM}-compatible accessory was used as a digital video connector to adapt 3.3V levels from the FPGA to CML (Current Mode Logic) compatible levels, suitable for generating DVI (Digital Video Interface) signals capable of driving an HDMI\textsuperscript{TM} display. The main board, a OrangeCrab \cite{orangecrab}, is shown in Fig. \ref{figboard} connected to the video adapter.
\item  A Digilent\textsuperscript{TM}  Arty A7 board based on an Artix7-100T FPGA, with the addition of a parallel RGB to DVI adapter.
\end{itemize}

\begin{figure}
\includegraphics[width=\columnwidth]{orangecrab.png}
\caption{Hardware prototype.}
\label{figboard}
\end{figure}

\subsection{Software Architecture}

To get the FPGA bitstream from the C sources, we integrated the following components:

\begin{itemize}
\item CflexHDL\cite{cflexhdl} for C++ parsing, fixed point types and arbitrary width floating point types, and vector of these using operator overloading
\item Clang’s cindex\cite{cindex} to help in parsing C++
\item PipelineC\cite{pipelinec} tool (C to VHDL with autopipelining)
\item A custom simulator capable of reading the CPU energy meters to estimate power usage, using the SDL\cite{sdllib} libraries for displaying the rendered graphics
\item Yosys\cite{yosys} tool for Verilog parsing and synthesis and NextPNR\cite{nextpnr} tool for place and route (ECP5 target)
\item AMD Vivado\textsuperscript{TM} for Verilog to bitstream generation (Artix7 target)
\item Verilator for logic level simulation
\item GHDL\cite{GHDL} from a Yosys plugin\cite{ghdlplugin} for VHDL to Verilog conversion (used by Verilator and for synthesis)
\item LiteX\cite{litex} for the SoC design of the test boards, and its video core with serialized digital outputs (DVI)
\end{itemize}


\subsection{Workflow}

The workflow allows writing algorithms involving complex types like structures, fixed and floating point numbers and operations on vectors of these, all composable using a clean and familiar C/C++ syntax.

\begin{lstlisting}[language=C++]
hit_out ray_sphere_intersect(vec3 center, point_and_dir hitin)
{
  vec3 rc = hitin.orig - center;
  float b =  dot(rc, hitin.dir);
  float c =  dot(rc, rc) - SPHERE_RADIUS*SPHERE_RADIUS;
  float diff = b*b - c;
  [...]
}
\end{lstlisting}

As shown in the above function (actual source from the raytracer), the prototype shows a 3D float vector data type is used as 1\textsuperscript{st} argument, and structures are used for the 2\textsuperscript{nd} argument and return type. In the first line of the function's body a subtraction operation is done between 3D float vector types, and in the following line there is a call to a function taking two 3D float vectors and returning a float scalar. This kind of flexibility and clean syntax makes for easy development of math-intensive algorithms, as used in graphics or general DSP (Digital Signal Processing). 

The source code is first converted by the CflexHDL tool from C++ to C, translating math operations over types to function calls. Then this subset of C is converted to VHDL by the PipelineC tool. To synthesize that output into a netlist, \texttt{ghdl} and \texttt{yosys} commands are used, with place and route done by \texttt{nextpnr}. Alternatively, the Vivado tool can generate the bitstream right from the generated VHDL files.

In addition to source conversion, the PipelineC tool is primarily the mechanism for producing pipelined digital logic from the pure combinatorial logic derived C code. The tool is aware of the FPGA timing characteristics for the specific device (by iterating with the synthesis tool) and adds pipelining as needed to meet timing. This avoids the tedious and error-prone task of manual pipelining that digital designers are familiar with. The tool reports a preliminary estimate of resources prior to synthesis and the amount of pipeline stages required to implement the user’s functionality.

\begin{figure}
\includegraphics[width=\columnwidth]{workflow.png}
\caption{Tool flow.}
\label{figflow}
\end{figure}

Alternatively, as shown on the left branch of Fig. \ref{figflow}, sources can be compiled and run “as C” as a kind of ultra-fast simulation. As another option, the Verilog sources can be processed by Verilator to generate C++ simulation code which is then run and used to show results graphically in the custom simulation setup we provide. An estimation of resource usage is also reported via instrumented C++ template classes and operator overloading that counts operations between fixed and/or float types. The precision of the fixed and float types can be arbitrarily set simply by changing constants in the source code. Then, using fast simulations, it is easy to iterate on the bit precision number to determine an optimal balance of resource usage v.s. visual graphics quality.

\section{Results}

We evaluated various aspects of the workflow: how development time is reduced, the maximum resolution achievable using standard video refresh rates, how the PipelineC tool iterated on the number of pipeline stages required to reach the target frequency, and the required precision of data types to meet resource usage requirements on each device (both tested cases). For comparison purposes we also measured the power required by the FPGA platform, and the power usage of a reference PC platform running the game as software.

\subsection{Required data types}

\begin{figure}
\includegraphics[width=\columnwidth]{float comparison.png}
\caption{Effect mantissa precision of float types. Left: 23 bits. Right: 14 bits.}
\label{figprec}
\end{figure}

To be able to fit the design into the the target devices, float types were represented with a 14 bit mantissa (instead of the typical 23 bits). Fixed point processing also needed to save resources, and a total of 22 bits was used: 12 for integer portion, 10 for the fractional bits. Those arbitrary-sized types are provided by the CflexHDL and PipelineC type libraries. The effects of the reduced precision can be readily appreciated with the provided graphical simulation tool, as shown in Fig. \ref{figprec}.

\subsection{Pipeline stages}


\begin{figure*}
\includegraphics[width=\textwidth]{pipeline.png}
\caption{Resulting pipeline for the ECP5 target.}
\label{figstages}
\end{figure*}

We selected a target of 148.5 MHz pixel clock on the Artix-7, required to meet standard FullHD video timings (1920x1080 at 60Hz). A 25MHz pixel clock target was set for the smaller ECP5, for compatibility with 640x480 pixels at 60Hz.
To meet the faster pixel clock on the Artix device, the PipelineC tool created a rendering pipeline of $\sim$400 stages, and $\sim$70 stages were necessary to meet the slower resolution on the ECP5 device. We happily remark that the latter platform allowed for a full open-source toolchain. The resulting pipeline stages for the ECP5 case are shown on Fig. \ref{figstages}. Common operations were subdivided as shown on Table \ref{tabopstages}.

\begin{table}
\caption{Stages per operation}
\begin{center}
\begin{tabular}{|c|c|}
\hline \textbf{Operation}&  \textbf{Stages} \\
\hline Fixed Compare & 1 stage \\
\hline Fixed Addition/Subtraction & 2 stages \\
\hline Fixed Multiplication & 2 stages \\
\hline Float Compare & 2 stages \\
\hline Float Multiplication & 2 stages \\
\hline Float Addition/Subtraction & 3 stages \\
\hline Float Fast Reciprocal & 3 stages \\
\hline Float Fast Reciprocal Square Root & 3 stages \\
\hline Float Fast Square Root & 3 stages \\
\hline Float Fast Division & 4 stages \\
\hline Float 3D Vector Dot Product & 5 stages \\
\hline Float 3D Vector Normalize & 7 stages \\
\hline Ray Plane Intersection & 10 stages \\
\hline Ray Sphere Intersection & 22 stages \\
\hline
\end{tabular}
\label{tabopstages}
\end{center}
\end{table}


\subsection{Tool running time}

The typical times for development/test cycles, as in Table \ref{tabtimings}, are quite fast as compared with the traditional workflows. Build time to run the project during normal devopment is less than a second using a typical PC.

\begin{table}
\caption{Tool running times}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline \textbf{Simulation kind} & \textbf{Build command}&  \textbf{Build time}& \textbf{Speed @1080p} \\
\hline CPU - Fast & \texttt{make sim} & 1s & 60-86 FPS \\
\hline CPU - Precise & \texttt{make gen} & 5s & 40FPS \\
\hline Logic & \texttt{make verilator} & 1min 50s & 50s per frame \\
\hline
\end{tabular}
\label{tabtimings}
\end{center}
\end{table}

\subsection{Pipelined system compared to a CPU architecture}

We compared our design with a quite powerful and modern CPU-based platform: a AMD Ryzen™ 4900H 8-core/16 threads 64-bit CPU @ up to 4.4GHz clock, fabricated using a 7nm silicon process, at 45W TDP (Thermal Design Power), running Linux in a desktop PC. Using the SIMD (Single Instruction Muliple Data) vector float processing offered by the CPU and compiler, we see performance doubled over doing part of the calculations in fixed point (as in the FPGA case). Indeed, the vector extensions and an all-floating point processing was required to reach 60 FPS (frames per second) at the same resolution as in FPGA. The C code for both targets was unchanged beyond simple type definitions to select between float or fixed types (\textit{typedef} C keyword), while the same syntax for math operations was kept by using C++ operator overloading. So the rendering source code remains exactly the same for running interchangeably on the CPU or in the FPGA, even when not all data types are the same.

Comparing a FPGA with a CPU is not an easy task: you can always use a bigger and more modern FPGA than the one we used, but we avoided too large devices on purpose. This is to make more accessible the test platforms, and ease reproduction of our results. Also, you can always use a CPU with more cores, bigger caches, faster clocks, smaller transistors, etc. But each time you add more silicon real estate to a computing platform and - in doing so achieve higher performance - the system will naturally will demand more power. Because of that, we think that evaluating the power consumption per operation is a good way to make a fair comparison.

When running the game on the PC platform, the system uses 97.5\% of the CPU (all cores/threads are active). It ran at 88ºC with the fans at their highest speed, and consumed 33W as reported by our simulator which accesses and reports the energy meters internal to the CPU (energy metering was disabled during any excess time after each frame was rendered). The average clock rate of the 16 threads was automatically set by the CPU at 4.220GHz (96\% of max clock), thus equivalent to 67.5GHz of a theoretical single-thread CPU. We remark that the power required for the external DDR4 memory bank is not taken into account, nor the energy needed to run fans, but those devices usually take several watts combined.

On the other hand we have our FPGA platform for achieving same resolution and FPS: a medium-sized and low cost chip from same vendor as the CPU, not requiring active cooling, and fabricated on a much older silicon process of 28nm instead of the 7nm of the CPU. We estimated that the FPGA packs just about 13\% of the transistor per mm\textsuperscript{2} based on average density for those silicon processes\cite{dennard}. Considering that the FPGA’s die size is about half as large (a gross estimation using die pictures having some size references) we calculated the FPGA has $\sim$15X less transistors and other silicon features compared to the CPU. The clock rate was set to 148.5MHz matching the requirements for the video generation, and the automatically generated pipeline resulted in 482 stages. A total of 135 hardware multipliers are run in parallel, used for floating point or integer/fixed point operations.

\begin{figure}
\includegraphics[width=1\columnwidth]{processing preformance.png}
\caption{Processing performance. Blue: CPU. Orange: FPGA}
\label{figperf}
\end{figure}

The full pipeline required 37Kbits of flip flops, corresponding to an average of 83 bits per operation, constituting a theoretical peak internal bandwidth of 5.4Tbit/s. Computing the 482 stages/$\sim$operations simultaneously at such frequency is roughly equivalent to theoretical 71.5GHz clock rate one operation per cycle execution, a number that closely matches the theoretical single-threaded CPU case.

The workload required to raytrace the FullHD image on the FPGA was on the order of 300 arithmetic and logic operations over integers, and about 150 floating point operations per pixel (including comparisons and optimized operations on just the exponent por power-of-two scalings), all running simultaneously at up to 148.5MHz rate.

Even with all these realtime compute demands, the power required by the FPGA core was just 660mW for the FullHD target resolution, and the chip stayed barely warm. So, our system having an order of magnitude less silicon resources, resulted in 50X less power consumption than a modern CPU running the same workload, or equivalently, a 50X processing performance improvement per unit power, as depicted in Fig. \ref{figperf}. We expect the efficiency gains could improve up to about 6X when using a more modern FPGA (if built on a 7nm process), since Dennard's law seems to hold at the set speed, see \cite{dennard}. The improvement could be even higher if the digital design were to be implemented in an ASIC, something that we plan to test.
\\

\section{Conclusions}

We showed a ready-to-use toolchain for hardware design based on a familiar programming language syntax that greatly accelerates development time by using fast simulators at different stages. The code can be translated to a logic circuit or run on an off-the-shelf CPU. An example application requiring complex processing was demonstrated by writing a game that implements the usual operations for raytracing applications, with a clean syntax for the math and the other algorithms. Since we apply an automatically calculated and possibly long pipeline, the system is capable of performing very well even compared to powerful modern CPUs, but using smaller and embeddable chips, at low power.
\\

The full source code associated with this work can be found on the project's repository \cite{mainrepo}.
\\

\section{About the authors}
This work is a result of the tight interactions between Julian Kemmerer and Victor Suarez Rovere during about a year.
\\

\textbf{Victor Suarez Rovere} is the author of CflexHDL tool used in this project (C++ parser/generator, math types library and simulation) and of the Sphery vs. Shapes raytraced game. He is a software and hardware developer and consultant experienced in Digital Signal Processing, mainly in the medical ﬁeld. Victor was awarded the ﬁrst prize in the Argentine National Technology contest, a gold medal from WIPO as “Best young inventor” and some patents related to a multitouch technology based on tomography techniques. 

\textbf{Julian Kemmerer} is the author of the PipelineC tool (C-like HDL with auto-pipelining) used in this work. He earned a Masters degree in Computer Engineering from Drexel University in Philadelphia where his work focused on EDA tooling. Julian currently works as an FPGA engineer at an AI focused SDR company called Deepwave Digital. He is a highly experienced digital logic designer looking to increase the usability of programmable devices by moving problems from hardware design into a familiar C language look.
\\

\begin{thebibliography}{00}

\bibitem{verilator} Verilator - open source Verilog/SystemVerilog logic simulator - 
\url{https://www.veripool.org/verilator/}

\bibitem{orangecrab} OrangeCrab board - \url{https://1bitsquared.com/products/orangecrab}

\bibitem{cflexhdl} CflexHDL tool - C to FPGA tool, type library, and fast simulator - 
\url{https://github.com/suarezvictor/CflexHDL}

\bibitem{cindex} Clang's cindex parser - 
\url{https://github.com/llvm-mirror/clang/blob/master/bindings/python/clang/cindex.py}

\bibitem{pipelinec} PipelineC tool - C to FPGA with autopipeliner -  \url{https://github.com/JulianKemmerer/PipelineC}

\bibitem{sdllib} SDL graphics and UI libraries - 
\url{https://www.libsdl.org/}

\bibitem{yosys} Yosys Verilog RTL synthesis tool - 
\url{https://yosyshq.net/yosys/}

\bibitem{nextpnr} NextPNR place and route tool - 
\url{https://github.com/YosysHQ/nextpnr}

\bibitem{GHDL} GHDL - open source VHDL simulator - 
\url{http://ghdl.free.fr/}

\bibitem{ghdlplugin} GHDL plugin for Yosys - 
\url{https://github.com/ghdl/ghdl-yosys-plugin}

\bibitem{litex} LiteX system-on-chip creator for FPGA platforms - 
\url{https://github.com/enjoy-digital/litex}

\bibitem{dennard} Nadine Collaert, 2016: Device architectures for the 5nm technology node and beyond - 
\url{https://bjpcjp.github.io/pdfs/chips/SEMICON_Taiwan_2016_collaert.pdf}

\bibitem{mainrepo} Sphery vs. Shapes repository - \url{https://github.com/JulianKemmerer/PipelineC-Graphics}

\end{thebibliography}
\end{document}

