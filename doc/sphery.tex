\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Sphery vs. Shapes: A hardware-only raytraced game\\

\author{
\IEEEauthorblockN{1\textsuperscript{st} Victor Suarez Rovere}
Buenos Aires, Argentina \\
suarezvictor@gmail.com
\and
\IEEEauthorblockN{2\textsuperscript{nd} Julian Kemmerer}
Philadelphia, USA \\
julian.v.kemmerer@gmail.com
}}

\maketitle

\begin{abstract}
In this article we present a tool flow that takes C++ code describing a raytraced game, and produces digital logic that can be implemented in off-the-shelf FPGAs (Field Programmable Gate Arrays) with no use of a hard or soft CPU. We aim for these tools to achieve a friendly C-to-FPGA flow, making the development and simulation process exceptionally fast and easy, while providing high performance and low power results in hardware.
\end{abstract}

\begin{IEEEkeywords}
FPGA, raytracing, DSP, simulation, transpiler, logic synthesis
\end{IEEEkeywords}

\section{Introduction}
Interactive ray tracing hardware is novel in FPGA (Field Programmable Gate Arrays) and our work serves as a perfect example that such complex data processing circuits can be developed, tested, and implemented in hardware all from a C language based flow that greatly eases the design process over traditional hardware description languages.

Ultra-fast compiled C based emulation and C++ based tools like Verilator\cite{verilator} allow for fast simulation with realtime debug. This quick workflow is essential, the possibility to compile-as-C and see the results of code changes executed in realtime becomes a requirement for developing a interactive game, something not possible with standard FPGA simulators.

The project generates each video pixel in hard-realtime “chasing the beam” fashion, without a frame buffer and with negligible jitter. A medium size AMD\textsuperscript{TM}  Artix-7\textsuperscript{TM} FPGAs have reached up to Full HD (1080p) and 60FPS (frames per second) using a 148.5MHz pixel clock. A Lattice\textsuperscript{TM}  ECP5\textsuperscript{TM} 85K FPGA reaches 480p at 60FPS, using a 25MHz pixel clock. Pipelining the entire ray tracer produces a position-to-color latency of a few microseconds at most. The 1080p case requires about 500 pipeline stages, and for 480p the requirement is about 70 stages; in both cases this pipelining is done automatically as part of the tool flow.

The Artix-7 FPGA achieves about 70 GFLOP/s using less than 1 watt, thanks to the dozens of hardware resources working in parallel. Using that 28nm AMD 7-series FPGA, power was calculated to be reduced 50 times compared with a modern 7nm CPU running heavily optimized vector instructions.
\\
\section{Workflow}

The workflow allows writing algorithms involving complex types like structures, floating point types and operations on vectors of these, while keeping a clean and familiar syntax.

\begin{figure}
\includegraphics[width=\columnwidth]{codeex.png}
\caption{Code portion of the raytracer.}
\label{figcodeex}
\end{figure}

As shown in the function prototype of Fig. \ref{figcodeex}, a 3D float vector data type is used as 1\textsuperscript{st} argument, and structures for the 2\textsuperscript{nd} argument and return type. In the first line of the function a subtraction operation is done between 3D float vector types, and in the following line a call to a function taking two 3D float vectors and returning a float scalar is used. This kind of flexibility and clean syntax makes for easy development of math-intensive algorithms used in graphics or general DSP. 

The source code is first converted by the CflexHDL\cite{cflexhdl} tool from C++ to C. Then this subset of C can be converted to VHDL by the PipelineC\cite{pipelinec} tool. To convert the output VHDL into netlists, \texttt{ghdl} and \texttt{yosys} commands are used to be processed with the \texttt{nextpnr} command, or alternatively, the AMD Vivado\textsuperscript{TM} tool can generate the bitstream right from the VHDL files. 

In addition to simple conversion to VHDL, PipelineC is primarily the mechanism for producing pipelined digital logic from the pure combinatorial logic derived from C code. PipelineC is aware of the FPGA timing characteristics of the specific device (by iterating with the synthesis tool) and adds pipelining as needed to meet timing. This avoids the tedious and error-prone task of manual pipelining that digital designers are familiar with. The flow reports a preliminary estimate of resources prior to synthesis and the amount of pipeline stages required to implement the user’s functionality.

\begin{figure}
\includegraphics[width=\columnwidth]{workflow.png}
\caption{Tool flow.}
\label{figflow}
\end{figure}


Alternatively, the sources can be compiled and run “as C”, as a kind of ultra-fast emulation/simulation: the game can be played in FullHD at 60FPS during debug on a PC, or the Verilog sources can be processed by Verilator to generate C++ simulation code, that’s used to show results graphically by another tool we provide. An estimation of resource usage is also reported by counting operations between fixed and float types, that's generated using instrumented C++ template classes and operator overloading.

The typical times for development/test cycles are as in Table \ref{tabtimings}, resulting comparatively quite fast as compared with the traditional workflows.
\\
\section{Hardware Architecture}

The project was tested on two platforms: a fully open source board based on a Lattice ECP5 FPGA with 85K LUTs (the OrangeCrab board \cite{orangecrab}) plus a Digilent\textsuperscript{TM} PMOD\textsuperscript{TM}-compatible digital video connector, and a Digilent Arty\textsuperscript{TM} A7 board that's based on an Artix7-100T FPGA with the addition of a parallel RGB to DVI board.

\begin{figure}
\includegraphics[width=\columnwidth]{orangecrab.png}
\caption{Hardware prototype.}
\label{figboard}
\end{figure}

\subsection{Automatic pipeline}

We use a 148.5 MHz pixel clock on the Artix-7 and a 25MHz pixel clock on the ECP5.
To meet the 148.5 MHz pixel clock on the Artix device, the PipelineC tool created a pixel rendering pipeline of $\sim$480 stages, and $\sim$70 stages to meet 25MHz on the Lattice ECP5 FPGA.

The resulting pipeline stages for the ECP5 case are shown on Fig. \ref{figstages}. Common operations are subdivided as shown on Table \ref{tabopstages}.

\begin{table}
\caption{Stages per operation}
\begin{center}
\begin{tabular}{|c|c|}
\hline \textbf{Operation}&  \textbf{Stages} \\
\hline Fixed Compare & 1 stage \\
\hline Fixed Addition/Subtraction & 2 stages \\
\hline Fixed Multiplication & 2 stages \\
\hline Float Compare & 2 stages \\
\hline Float Multiplication & 2 stages \\
\hline Float Addition/Subtraction & 3 stages \\
\hline Float Fast Reciprocal & 3 stages \\
\hline Float Fast Reciprocal Square Root & 3 stages \\
\hline Float Fast Square Root & 3 stages \\
\hline Float Fast Division & 4 stages \\
\hline Float 3D Vector Dot Product & 5 stages \\
\hline Float 3D Vector Normalize & 7 stages \\
\hline Ray Plane Intersection & 10 stages \\
\hline Ray Sphere Intersection & 22 stages \\
\hline
\end{tabular}
\label{tabopstages}
\end{center}
\end{table}


\begin{figure*}
\includegraphics[width=\textwidth]{pipeline.png}
\caption{Resulting pipeline for the ECP5 target.}
\label{figstages}
\end{figure*}


\subsection{Data types}
In this application, float types are implemented with a 14 bit mantissa (instead of the typical 23 bits), and fixed point values are represented with a total of 22 bits: 12 for integer portion, 10 for the fractional bits. Those arbitrary-sized types are provided by the CflexHDL type library. The effects of reduced precision can be readily appreciated with the provided graphical simulation tool, as shown in Fig. \ref{figprec}.
By performing the fast simulations, it's easy to iterate the bit number to visually determine the optimal bit width.

\begin{figure}
\includegraphics[width=\columnwidth]{float comparison.png}
\caption{Effect mantissa precision of float types. Left: 23 bits. Right: 14 bits.}
\label{figprec}
\end{figure}

\section{Software Architecture}

To get the FPGA bitstream from the C sources, we integrated the following components:

\begin{itemize}
\item PipelineC for C to VHDL, autopipelining (uses pycparser\cite{pycparser})
\item CflexHDL for C++ parsing, fixed point types and arbitrary width floating point types, and vector of these using operator overloading
\item Clang’s cindex\cite{cindex} to help in parsing C++
Verilator for logic level simulation
\item Custom simulator based on the SDL\cite{sdllib} libraries (used when compiling the raytracer, or after Verilator C++ generation)
\item Yosys\cite{yosys} tool for Verilog parsing and synthesis and NextPNR\cite{nextpnr} tool for place and route (ECP5 target)
\item AMD Vivado for Verilog to bitstream generation (Artix7 target)
\item GHDL\cite{GHDL} from a Yosys plugin\cite{ghdlplugin} for VHDL to Verilog conversion (used by Verilator and for synthesis)
\item LiteX\cite{litex} for the SoC design of the test boards, and its video core with serialized digital outputs (DVI)
\end{itemize}

\begin{table}
\caption{Tool running times}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline & \textbf{Build command}&  \textbf{Build time}& \textbf{Speed @1080p} \\
\hline Fast CPU simulation & \texttt{make sim} & 1s & 60-86 FPS \\
\hline Precise CPU simulation & \texttt{make gen} & 5s & 40FPS \\
\hline Logic simulation & \texttt{make verilator} & 1min 50s & 50s per frame \\
\hline
\end{tabular}
\label{tabtimings}
\end{center}
\end{table}


\section{Pipelined system compared to a CPU architecture}


The workload required to raytrace the 1920x1080 pixel image was on the order of 300 arithmetic and logic operations over integers and about 150 floating point operations per pixel (including comparisons and optimized operations on just the exponent por power-of-two scalings), all running at up to 148.5MHz rate, so about 67 Gop/s if data movements are not counted.

We compared our design with a quite powerful and modern CPU-based platform: a AMD Ryzen™ 4900H 8-core/16 threads 64-bit CPU @ up to 4.4GHz clock, fabricated using a 7nm silicon process, at 45W TDP (running Linux in a desktop PC). Using the SIMD vector float processing offered by the CPU we see performance doubled over using some calculations in fixed points, as used in the FPGA. Indeed, the vector extensions and an all-floating point processing was required to reach 60 FPS at the same resolution as in the FPGA. The C code for both targets was unchanged beyond simple type definitions (\textit{typedef} C keyword) to select between float or fixed types to be used in the implementation, while the same syntax for math operations was kept by using C++ operator overloading. So the processing source code remains exactly the same for running interchangeably on the CPU or in the FPGA.

Comparing a FPGA with a CPU is not an easy task: you can always use a bigger and more modern FPGA than the one we used, but they were selected not to be too large on purpose to make more accessible the test platforms. Also, you can also always use a CPU with more cores, bigger caches, faster clocks, smaller transistors, etc. but each time you add more silicon real estate to a computing platform -in order to achieve higher performance- that naturally makes the system require more power. Because of that, we think that evaluating the power consumption per operation is a good way of trying to make a fair comparison.


When running the game on the CPU, the system uses 97.5\% of the CPU (all cores/threads are active). It ran at 88ºC with the fans at their highest speed, and consumed 33W as reported by our simulator, which accesses and reports the energy meters internal to the CPU. For any excess time after the frame is rendered, the energy metering was stopped. The average clock rate of the 16 threads was automatically set at 4.220GHz (96\% of max clock), thus equivalent to 67.5GHz of a theoretical single-thread CPU. We remark that the power required for the external DDR4 memory bank is not taken into account, nor the energy needed to run fans, but those devices usually take several watts combined.

On the other hand there’s our FPGA platform for achieving same resolution and FPS: a medium-sized ( $\sim$100K logic elements) and low cost chip from same vendor as the CPU, not requiring active cooling, and fabricated on a much older silicon process of 28nm instead of the 7nm of the CPU (packing just about 13\% transistor per mm2). Considering that the FPGA’s die size is about half as large we estimate 15X less transistors (and other silicon features) compared to the CPU. The FPGA clock rate was set to 148.5MHz matching the requirements for the video generation, and the automatically generated pipeline resulted in 482 stages. A total of 135 hardware multipliers are run in parallel, used by floating point or integer/fixed point operations.

\begin{figure}
\includegraphics[width=1\columnwidth]{processing preformance.png}
\caption{Processing performance. Blue: CPU. Orange: FPGA}
\label{figperf}
\end{figure}

The full pipeline required 37Kbits of flip flops, corresponding to an average of 83 bits per operation, constituting a theoretical peak internal bandwidth of 5.4Tbit/s. Computing the 482 stages/$\sim$operations simultaneously at 148.5MHz is roughly equivalent to a 71.5GHz clock rate if it could ran in a serial form, a number that closely matches the theoretical single cycle/threaded CPU case.


Even with all these realtime compute demands, the power required by the FPGA core was just 660mW for the FullHD graphics, and the chip stayed barely warm. So, our FPGA system, with an order of magnitude less silicon resources, resulted in 50X less power consumption than a modern CPU to cope with the same workload, or equivalently, a processing performance improvement per unit power as depicted in Fig. \ref{figperf}.

We expect the efficiency gains could improve up to about 6X when using a more modern FPGA (if built on a 7nm process), since Dennard's law seems to hold at the set speed, see \cite{dennard}. The improvement could be even higher if the digital design were to be implemented in an ASIC, something that we plan to test.
\\

\section{Conclusions}

We showed a ready-to-use toolchain for hardware design that greatly accelerates development time by using fast simulators at different stages, based on a known programming language and syntax. The code can be translated to a logic circuit or run on an off-the-shelf CPU. An example application requiring complex processing was demonstrated by writing a game that implements the usual math operations for raytracing applications, with a clean syntax for math and all the algorithms. Since we apply an automatically calculated -and possibly long- pipeline, the system is capable of performing very well even compared to powerful modern CPUs, but using smaller and embeddable chips, at low power. \\
The full source code for this project can be found on the project's repository \cite{mainrepo}.
\\

\section{About the authors}
This work is a result of the tight interactions between Julian Kemmerer (\@pipelinec\_hdl; fosstodon.org/\@pipelinec) and Victor Suarez Rovere (Twitter: \@suarezvictor) during almost a year.

\textbf{Victor Suarez Rovere} is the author of CflexHDL tool used in this project (parser/generator, math types library and simulation) and of the Sphery vs. Shapes game. He’s a software and hardware developer and consultant experienced in Digital Signal Processing, mainly in the medical ﬁeld. Victor was awarded the ﬁrst prize in the Argentine National Technology contest, a gold medal from WIPO as “Best young inventor” and some patents related to a multitouch technology based on tomography techniques.

\textbf{Julian Kemmerer} is the author of the PipelineC tool (C-like HDL w/ auto-pipelining) used in this work. He earned a Masters degree in Computer Engineering from Drexel University in Philadelphia where his work focused on EDA tooling. Julian currently works as an FPGA engineer at an AI focused SDR company called Deepwave Digital. He is a highly experienced digital logic designer looking to increase the usability of FPGAs by moving problems from hardware design into a familiar C language look.

\begin{thebibliography}{00}

\bibitem{dennard} Nadine Collaert: Device architectures for the 5nm technology node and beyond, 
\url{https://bjpcjp.github.io/pdfs/chips/SEMICON_Taiwan_2016_collaert.pdf}

\bibitem{mainrepo} Sphery vs. Shapes repository, \url{https://github.com/JulianKemmerer/PipelineC-Graphics}

\bibitem{orangecrab} OrangeCrab board, \url{https://1bitsquared.com/products/orangecrab}

\bibitem{cflexhdl} CFlexHDL tool - C to FPGA tool, type library, and fast simulator \url{https://github.com/suarezvictor/CflexHDL}

\bibitem{pipelinec} PipelineC tool - C to FPGA with autopipeliner \url{https://github.com/JulianKemmerer/PipelineC}

\bibitem{pycparser} PyCParser parser library
\url{https://github.com/JulianKemmerer/PipelineC}

\bibitem{cindex} Clang's cindex parser
\url{https://github.com/llvm-mirror/clang/blob/master/bindings/python/clang/cindex.py}

\bibitem{sdllib} SDL graphics and UI libraries
\url{https://www.libsdl.org/}

\bibitem{yosys} Yosys Verilog RTL synthesis tool
\url{https://yosyshq.net/yosys/}

\bibitem{nextpnr} NextPNR place and route tool
\url{https://github.com/YosysHQ/nextpnr}

\bibitem{verilator} Verilator - open source Verilog/SystemVerilog logic simulator
\url{https://www.veripool.org/verilator/}

\bibitem{GHDL} GHDL - open source VHDL simulator
\url{http://ghdl.free.fr/}

\bibitem{ghdlplugin} GHDL plugin for Yosys
\url{https://github.com/ghdl/ghdl-yosys-plugin}

\bibitem{litex} LiteX system-on-chip creator for FPGA platforms
\url{https://github.com/enjoy-digital/litex}

\end{thebibliography}
\end{document}
